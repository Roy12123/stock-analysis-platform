#!/usr/bin/env python3
"""
æ¯æ—¥è™•ç½®è‚¡ç¥¨é è­¦ç³»çµ±
åŸ·è¡Œæµç¨‹ï¼š
1. çˆ¬å–æœ€æ–°æ³¨æ„è‚¡ç¥¨å…¬å‘Š
2. åˆ†ææ­·å²è¨˜éŒ„ï¼Œé æ¸¬æ˜å¤©å¯èƒ½è¢«è™•ç½®çš„è‚¡ç¥¨
3. è¨ˆç®—æ˜å¤©çš„è§¸ç™¼é–€æª»ï¼ˆåƒ¹æ ¼ã€æ¼²è·Œå¹…ç­‰ï¼‰
4. è¼¸å‡ºé è­¦å ±å‘Š
"""

from datetime import datetime, timedelta
from crawl_attention_stocks import TWSEAttentionStockCrawler
from disposal_predictor import DisposalPredictor
import pandas as pd
import os


def main():
    """ä¸»ç¨‹å¼"""
    print("="*80)
    print(" "*25 + "è™•ç½®è‚¡ç¥¨æ¯æ—¥é è­¦ç³»çµ±")
    print("="*80)
    print(f"åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

    # ===== æ­¥é©Ÿ1: çˆ¬å–æœ€æ–°æ³¨æ„è‚¡ç¥¨ =====
    print("\nã€æ­¥é©Ÿ1ã€‘çˆ¬å–æœ€æ–°æ³¨æ„è‚¡ç¥¨å…¬å‘Š...")
    print("-"*80)

    # åˆå§‹åŒ–çˆ¬èŸ²ï¼ˆä¸éæ¿¾è‚¡ç¥¨æ¸…å–®ï¼Œé¡¯ç¤ºæ‰€æœ‰æ³¨æ„è‚¡ç¥¨ï¼‰
    crawler = TWSEAttentionStockCrawler(stock_list_path=None)

    # çˆ¬å–æœ€è¿‘30å¤©çš„è³‡æ–™ï¼ˆç¢ºä¿æœ‰è¶³å¤ çš„æ­·å²è¨˜éŒ„ï¼‰
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)

    attention_df = crawler.fetch_date_range(
        start_date.strftime('%Y%m%d'),
        end_date.strftime('%Y%m%d')
    )

    if attention_df.empty:
        print("\nâš ï¸  è¿‘30å¤©ç„¡æ³¨æ„è‚¡ç¥¨è³‡æ–™")

        # å»ºç«‹ç©ºçš„è¼¸å‡ºæª”æ¡ˆ
        df_empty = pd.DataFrame(columns=[
            'è‚¡ç¥¨ä»£ç¢¼', 'å…¬å¸åç¨±', 'é¢¨éšªç­‰ç´š',
            'ç´¯è¨ˆæ³¨æ„è‚¡æ¬¡æ•¸', 'é€£çºŒå¤©æ•¸', 'é æ¸¬è™•ç½®åŸå› ',
            'æœ€æ–°æ”¶ç›¤åƒ¹', 'æ¼²å¹…é–€æª»', 'è·Œå¹…é–€æª»'
        ])

        output_file = '../data/latest/è™•ç½®æ³¨æ„è‚¡.csv' if os.path.exists('../data/latest') else 'data/latest/è™•ç½®æ³¨æ„è‚¡.csv'
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        df_empty.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ… ç©ºçµæœå·²å„²å­˜è‡³: {output_file}")
        print("="*80)
        return

    # æ¸…ç†ä¸¦å„²å­˜æ­·å²è³‡æ–™ï¼ˆè‡¨æ™‚æª”æ¡ˆï¼‰
    clean_df = crawler.parse_and_clean_data(attention_df)

    # ä½¿ç”¨è‡¨æ™‚æª”æ¡ˆè·¯å¾‘
    temp_history_file = f'æ³¨æ„è‚¡ç¥¨_æ­·å²_{datetime.now().strftime("%Y%m%d")}.csv'
    temp_history_path = os.path.join(os.path.dirname(__file__), temp_history_file)
    clean_df.to_csv(temp_history_path, index=False, encoding='utf-8-sig')

    print(f"\nâœ“ æˆåŠŸæŠ“å– {len(clean_df)} ç­†æ³¨æ„è‚¡ç¥¨è¨˜éŒ„")
    print(f"âœ“ æ¶µè“‹ {clean_df['è­‰åˆ¸ä»£è™Ÿ'].nunique()} æª”ä¸åŒè‚¡ç¥¨")

    # ===== æ­¥é©Ÿ2: åˆ†æä¸¦é æ¸¬è™•ç½®è‚¡ç¥¨ =====
    print("\nã€æ­¥é©Ÿ2ã€‘åˆ†ææ³¨æ„è‚¡æ­·å²ï¼Œé æ¸¬æ˜å¤©å¯èƒ½è¢«è™•ç½®çš„è‚¡ç¥¨...")
    print("-"*80)

    predictor = DisposalPredictor()
    predictions = predictor.predict_tomorrow_disposal(temp_history_path)

    if predictions.empty:
        print("\nâœ“ ç›®å‰ç„¡è‚¡ç¥¨é”åˆ°è™•ç½®æ¨™æº–")

        # å»ºç«‹ç©ºçš„è¼¸å‡ºæª”æ¡ˆ
        df_empty = pd.DataFrame(columns=[
            'è‚¡ç¥¨ä»£ç¢¼', 'å…¬å¸åç¨±', 'é¢¨éšªç­‰ç´š',
            'ç´¯è¨ˆæ³¨æ„è‚¡æ¬¡æ•¸', 'é€£çºŒå¤©æ•¸', 'é æ¸¬è™•ç½®åŸå› ',
            'æœ€æ–°æ”¶ç›¤åƒ¹', 'æ¼²å¹…é–€æª»', 'è·Œå¹…é–€æª»'
        ])

        output_file = '../data/latest/è™•ç½®æ³¨æ„è‚¡.csv' if os.path.exists('../data/latest') else 'data/latest/è™•ç½®æ³¨æ„è‚¡.csv'
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        df_empty.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ… ç©ºçµæœå·²å„²å­˜è‡³: {output_file}")

        # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
        if os.path.exists(temp_history_path):
            os.remove(temp_history_path)

        print("="*80)
        return

    print(f"\nâš ï¸  ç™¼ç¾ {len(predictions)} æª”è‚¡ç¥¨å¯èƒ½è¢«è™•ç½®ï¼")

    # ===== æ­¥é©Ÿ3: è¼¸å‡ºè©³ç´°é è­¦å ±å‘Šï¼ˆçµ‚ç«¯æ©Ÿé¡¯ç¤ºï¼‰=====
    print("\nã€æ­¥é©Ÿ3ã€‘è™•ç½®é è­¦æ˜ç´°å ±å‘Š")
    print("="*80)

    for idx, row in predictions.iterrows():
        print(f"\nè‚¡ç¥¨ {idx+1}: {row['è­‰åˆ¸ä»£è™Ÿ']} {row['è­‰åˆ¸åç¨±']}")
        print(f"{'-'*80}")
        print(f"é¢¨éšªç­‰ç´š: {'ğŸ”´' if row['é¢¨éšªç­‰ç´š'] in ['æ¥µé«˜', 'é«˜'] else 'ğŸŸ¡'} {row['é¢¨éšªç­‰ç´š']}")
        print(f"é æ¸¬åŸå› : {row['é æ¸¬è™•ç½®åŸå› ']}")
        print(f"")
        print(f"æ³¨æ„è‚¡çµ±è¨ˆ:")
        print(f"  - ç´¯è¨ˆæ¬¡æ•¸: {row['ç´¯è¨ˆæ³¨æ„è‚¡æ¬¡æ•¸']}æ¬¡")
        print(f"  - é€£çºŒå¤©æ•¸: {row['é€£çºŒå¤©æ•¸']}å¤©")
        print(f"")
        print(f"æœ€æ–°è‚¡åƒ¹:")
        print(f"  - æœ€æ–°æ”¶ç›¤: {row['æœ€æ–°æ”¶ç›¤åƒ¹']}")
        print(f"")
        print(f"æ˜å¤©è§¸ç™¼æ³¨æ„è‚¡çš„é–€æª»:")
        print(f"  - æ¼²å¹…è¶…é: {row['æ¼²å¹…é–€æª»']}")
        print(f"  - è·Œå¹…è¶…é: {row['è·Œå¹…é–€æª»']}")

    # ===== æ­¥é©Ÿ4: å„²å­˜ç‚ºç¶²ç«™ç”¨çš„ CSV =====
    print("\n" + "="*80)
    print("ã€æ­¥é©Ÿ4ã€‘å„²å­˜ç¶²ç«™ç”¨ CSV...")
    print("-"*80)

    # é¸æ“‡éœ€è¦çš„æ¬„ä½ä¸¦é‡æ–°å‘½å
    predictions_web = predictions[[
        'è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±', 'é¢¨éšªç­‰ç´š',
        'ç´¯è¨ˆæ³¨æ„è‚¡æ¬¡æ•¸', 'é€£çºŒå¤©æ•¸', 'é æ¸¬è™•ç½®åŸå› ',
        'æœ€æ–°æ”¶ç›¤åƒ¹', 'æ¼²å¹…é–€æª»', 'è·Œå¹…é–€æª»'
    ]].copy()

    # é‡æ–°å‘½åæ¬„ä½
    predictions_web.columns = [
        'è‚¡ç¥¨ä»£ç¢¼', 'å…¬å¸åç¨±', 'é¢¨éšªç­‰ç´š',
        'ç´¯è¨ˆæ³¨æ„è‚¡æ¬¡æ•¸', 'é€£çºŒå¤©æ•¸', 'é æ¸¬è™•ç½®åŸå› ',
        'æœ€æ–°æ”¶ç›¤åƒ¹', 'æ¼²å¹…é–€æª»', 'è·Œå¹…é–€æª»'
    ]

    # å„²å­˜åˆ° data/latest ç›®éŒ„
    output_file = '../data/latest/è™•ç½®æ³¨æ„è‚¡.csv' if os.path.exists('../data/latest') else 'data/latest/è™•ç½®æ³¨æ„è‚¡.csv'
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    predictions_web.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ“ ç¶²ç«™ç”¨ CSV å·²å„²å­˜: {output_file}")

    # ===== çµ±è¨ˆæ‘˜è¦ =====
    print("\n" + "="*80)
    print("çµ±è¨ˆæ‘˜è¦")
    print("="*80)
    print(f"æ¥µé«˜é¢¨éšª: {len(predictions[predictions['é¢¨éšªç­‰ç´š']=='æ¥µé«˜'])} æª”")
    print(f"é«˜é¢¨éšª:   {len(predictions[predictions['é¢¨éšªç­‰ç´š']=='é«˜'])} æª”")
    print(f"ä¸­é¢¨éšª:   {len(predictions[predictions['é¢¨éšªç­‰ç´š']=='ä¸­'])} æª”")
    print(f"ä½é¢¨éšª:   {len(predictions[predictions['é¢¨éšªç­‰ç´š']=='ä½'])} æª”")

    print("\né«˜é¢¨éšªè‚¡ç¥¨æ¸…å–®:")
    high_risk = predictions[predictions['é¢¨éšªç­‰ç´š'].isin(['æ¥µé«˜', 'é«˜'])]
    for _, row in high_risk.iterrows():
        print(f"  ğŸ”´ {row['è­‰åˆ¸ä»£è™Ÿ']} {row['è­‰åˆ¸åç¨±']:8s} - {row['é æ¸¬è™•ç½®åŸå› ']}")

    # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
    if os.path.exists(temp_history_path):
        os.remove(temp_history_path)
        print(f"\nâœ“ å·²æ¸…ç†è‡¨æ™‚æª”æ¡ˆ: {temp_history_file}")

    print("\n" + "="*80)
    print("åŸ·è¡Œå®Œæˆï¼")
    print("="*80)


if __name__ == '__main__':
    main()
