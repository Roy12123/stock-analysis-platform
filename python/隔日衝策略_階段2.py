"""
éš”æ—¥è¡ç­–ç•¥ - éšæ®µ2: å³æ™‚ç¯©é¸
åŸ·è¡Œæ™‚é–“: æ¯æ—¥ä¸‹åˆ 13:20 å°åŒ—æ™‚é–“
åŠŸèƒ½: æŠ“å–å³æ™‚åƒ¹æ ¼,å¥—ç”¨ç¯©é¸æ¢ä»¶,è¼¸å‡ºç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨
"""

import requests
import pandas as pd
from datetime import datetime
import time
import os

def print_separator(char="=", length=80):
    print(char * length)

def print_header(text):
    print_separator()
    print(text)
    print_separator()

def load_token():
    """å¾ç’°å¢ƒè®Šæ•¸æˆ–æª”æ¡ˆè®€å– FinMind API Token"""
    # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å– (GitHub Actions)
    token = os.environ.get('FINMIND_TOKEN', '')
    if token:
        print("âœ… å¾ç’°å¢ƒè®Šæ•¸è®€å– Token")
        return token

    # æœ¬åœ°æ¸¬è©¦æ™‚å¾æª”æ¡ˆè®€å–
    try:
        with open('./token', 'r') as f:
            token = f.read().strip()
            print("âœ… å¾æª”æ¡ˆè®€å– Token")
            return token
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° Token")
        raise

def realtime_screen(token):
    """
    éšæ®µ2ï¼šå³æ™‚ç¯©é¸
    """
    print_header(f"éšæ®µ2ï¼šå³æ™‚ç¯©é¸ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    headers = {"Authorization": f"Bearer {token}"}

    # è®€å–æ­·å²è³‡æ–™
    print("\n[1/3] è®€å–æ­·å²è³‡æ–™...")
    # æ”¯æ´å¾ python/ ç›®éŒ„æˆ–æ ¹ç›®éŒ„åŸ·è¡Œ
    historical_file = '../data/latest/éš”æ—¥è¡_æ­·å²è³‡æ–™.csv' if os.path.exists('../data/latest/éš”æ—¥è¡_æ­·å²è³‡æ–™.csv') else 'data/latest/éš”æ—¥è¡_æ­·å²è³‡æ–™.csv'

    try:
        df_historical = pd.read_csv(historical_file)
        # ç¢ºä¿è‚¡ç¥¨ä»£ç¢¼æ˜¯å­—ä¸²å‹æ…‹
        df_historical['è‚¡ç¥¨ä»£ç¢¼'] = df_historical['è‚¡ç¥¨ä»£ç¢¼'].astype(str)
        print(f"âœ… æˆåŠŸè®€å– {len(df_historical)} æª”è‚¡ç¥¨çš„æ­·å²è³‡æ–™")
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ° {historical_file}")
        print("   è«‹ç¢ºèªéšæ®µ1å·²åŸ·è¡Œå®Œæˆ")
        return False

    # æŠ“å–å³æ™‚åƒ¹æ ¼ï¼ˆåˆ†æ‰¹æŸ¥è©¢ + é‡è©¦æ©Ÿåˆ¶ï¼‰
    print("\n[2/3] æŠ“å–å³æ™‚åƒ¹æ ¼...")
    all_stock_ids = df_historical['è‚¡ç¥¨ä»£ç¢¼'].astype(str).tolist()
    url_realtime = "https://api.finmindtrade.com/api/v4/taiwan_stock_tick_snapshot"

    # åˆ†æ‰¹æŸ¥è©¢ï¼ˆæ¯æ‰¹500æª”ï¼Œé¿å…URLéé•·ï¼‰
    batch_size = 500
    batches = [all_stock_ids[i:i+batch_size] for i in range(0, len(all_stock_ids), batch_size)]

    print(f"  å°‡ {len(all_stock_ids)} æª”è‚¡ç¥¨åˆ†æˆ {len(batches)} æ‰¹æŸ¥è©¢")

    all_realtime_data = []
    max_retries = 10

    for batch_idx, batch in enumerate(batches, 1):
        print(f"\n  æŸ¥è©¢ç¬¬ {batch_idx}/{len(batches)} æ‰¹ ({len(batch)} æª”)...")

        success = False
        for attempt in range(1, max_retries + 1):
            try:
                if attempt > 1:
                    print(f"    ç¬¬ {attempt} æ¬¡å˜—è©¦...")

                parameter = {"data_id": batch}
                resp = requests.get(url_realtime, headers=headers, params=parameter, timeout=30)

                if resp.status_code != 200:
                    print(f"    âš ï¸  HTTP {resp.status_code}")
                    if attempt < max_retries:
                        print(f"    ç­‰å¾…2ç§’å¾Œé‡è©¦...")
                        time.sleep(2)
                        continue
                    else:
                        print(f"    å›æ‡‰: {resp.text[:200]}")
                        break

                if not resp.text or len(resp.text.strip()) == 0:
                    print(f"    âš ï¸  ç©ºç™½å›æ‡‰")
                    if attempt < max_retries:
                        time.sleep(2)
                        continue
                    else:
                        break

                try:
                    data = resp.json()
                except Exception as json_error:
                    print(f"    âš ï¸  JSONè§£æå¤±æ•—: {json_error}")
                    if attempt < max_retries:
                        time.sleep(2)
                        continue
                    else:
                        break

                if "data" in data and len(data["data"]) > 0:
                    all_realtime_data.extend(data["data"])
                    print(f"    âœ… æˆåŠŸå–å¾— {len(data['data'])} æª”")
                    success = True
                    break
                else:
                    print(f"    âš ï¸  ç„¡è³‡æ–™")
                    if "msg" in data:
                        print(f"    è¨Šæ¯: {data['msg']}")
                    if attempt < max_retries:
                        time.sleep(2)
                        continue

            except requests.exceptions.Timeout:
                print(f"    âš ï¸  é€¾æ™‚")
                if attempt < max_retries:
                    time.sleep(2)
                    continue
            except Exception as e:
                print(f"    âš ï¸  éŒ¯èª¤: {e}")
                if attempt < max_retries:
                    time.sleep(2)
                    continue

        if not success:
            print(f"    âŒ ç¬¬ {batch_idx} æ‰¹æŸ¥è©¢å¤±æ•—ï¼ˆå·²å˜—è©¦{max_retries}æ¬¡ï¼‰")

        # æ‰¹æ¬¡é–“ç¨å¾®å»¶é²
        if batch_idx < len(batches):
            time.sleep(0.5)

    if len(all_realtime_data) == 0:
        print("\nâŒ æ²’æœ‰æˆåŠŸå–å¾—ä»»ä½•å³æ™‚è³‡æ–™")
        return False

    df_realtime = pd.DataFrame(all_realtime_data)
    print(f"\nâœ… ç¸½å…±æˆåŠŸå–å¾— {len(df_realtime)} æª”è‚¡ç¥¨çš„å³æ™‚è³‡æ–™")

    # ç¢ºä¿æ•¸å€¼å‹æ…‹æ­£ç¢º
    df_realtime['open'] = pd.to_numeric(df_realtime['open'], errors='coerce')
    df_realtime['close'] = pd.to_numeric(df_realtime['close'], errors='coerce')
    df_realtime['high'] = pd.to_numeric(df_realtime['high'], errors='coerce')
    df_realtime['low'] = pd.to_numeric(df_realtime['low'], errors='coerce')
    df_realtime['total_volume'] = pd.to_numeric(df_realtime['total_volume'], errors='coerce')
    df_realtime['change_rate'] = pd.to_numeric(df_realtime['change_rate'], errors='coerce')

    # å¥—ç”¨ç¯©é¸æ¢ä»¶
    print("\n[3/3] å¥—ç”¨ç¯©é¸æ¢ä»¶...")

    df_combined = df_historical.merge(
        df_realtime,
        left_on='è‚¡ç¥¨ä»£ç¢¼',
        right_on='stock_id',
        how='inner'
    )

    print(f"  åˆä½µå¾Œç¸½å…± {len(df_combined)} æª”è‚¡ç¥¨")

    # è¨ˆç®—ç•¶æ—¥å¯¦é«”ã€ä¸Šä¸‹å½±ç·š
    df_combined['current_body'] = abs(df_combined['close'] - df_combined['open'])
    df_combined['upper_shadow'] = df_combined['high'] - df_combined[['open', 'close']].max(axis=1)
    df_combined['lower_shadow'] = df_combined[['open', 'close']].min(axis=1) - df_combined['low']

    df_filtered = df_combined.copy()
    initial_count = len(df_filtered)

    # æ¢ä»¶1: ç´…Kæ£’
    df_filtered = df_filtered[df_filtered['close'] > df_filtered['open']]
    print(f"  âœ… æ¢ä»¶1 (ç´…Kæ£’): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {initial_count - len(df_filtered)} æª”)")

    # æ¢ä»¶2: å¯¦é«” > å‰æ—¥1.5å€
    cond2_count = len(df_filtered)
    df_filtered = df_filtered[df_filtered['current_body'] > df_filtered['prev_body'] * 1.5]
    print(f"  âœ… æ¢ä»¶2 (å¯¦é«”>å‰æ—¥1.5å€): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {cond2_count - len(df_filtered)} æª”)")

    # æ¢ä»¶3: é‡ > 5æ—¥å‡é‡2å€
    cond3_count = len(df_filtered)
    df_filtered = df_filtered[df_filtered['total_volume'] > df_filtered['avg_volume_5d'] * 2]
    print(f"  âœ… æ¢ä»¶3 (é‡>5æ—¥å‡é‡2å€): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {cond3_count - len(df_filtered)} æª”)")

    # æ¢ä»¶4: ä¸Šå½±ç·š < å¯¦é«”30%
    cond4_count = len(df_filtered)
    df_filtered = df_filtered[
        (df_filtered['current_body'] > 0) &
        (df_filtered['upper_shadow'] < df_filtered['current_body'] * 0.3)
    ]
    print(f"  âœ… æ¢ä»¶4 (ä¸Šå½±ç·š<å¯¦é«”30%): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {cond4_count - len(df_filtered)} æª”)")

    # æ¢ä»¶5: ä¸‹å½±ç·š < å¯¦é«”30%
    cond5_count = len(df_filtered)
    df_filtered = df_filtered[
        (df_filtered['current_body'] > 0) &
        (df_filtered['lower_shadow'] < df_filtered['current_body'] * 0.3)
    ]
    print(f"  âœ… æ¢ä»¶5 (ä¸‹å½±ç·š<å¯¦é«”30%): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {cond5_count - len(df_filtered)} æª”)")

    # æ¢ä»¶6: æ”¶åœ¨é«˜é»
    cond6_count = len(df_filtered)
    df_filtered = df_filtered[df_filtered['close'] >= df_filtered['high'] * 0.98]
    print(f"  âœ… æ¢ä»¶6 (æ”¶åœ¨é«˜é»): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {cond6_count - len(df_filtered)} æª”)")

    # æ¢ä»¶7: é‡ >= 10000å¼µ
    cond7_count = len(df_filtered)
    df_filtered = df_filtered[df_filtered['total_volume'] >= 10000]
    print(f"  âœ… æ¢ä»¶7 (é‡>=10000å¼µ): {len(df_filtered)} æª”ç¬¦åˆ (ç¯©æ‰ {cond7_count - len(df_filtered)} æª”)")

    print(f"\nğŸ¯ æœ€çµ‚ç¯©é¸çµæœ: {len(df_filtered)} æª”è‚¡ç¥¨ç¬¦åˆæ‰€æœ‰æ¢ä»¶")

    # æ•´ç†è¼¸å‡ºè³‡æ–™
    if len(df_filtered) > 0:
        df_output = df_filtered[[
            'è‚¡ç¥¨ä»£ç¢¼', 'å…¬å¸åç¨±', 'close', 'change_rate',
            'foreign_yesterday', 'foreign_3days',
            'trust_yesterday', 'trust_3days'
        ]].copy()

        df_output.columns = [
            'è‚¡ç¥¨ä»£ç¢¼', 'å…¬å¸åç¨±', 'ç•¶ä¸‹åƒ¹æ ¼', 'ç•¶ä¸‹æ¼²è·Œå¹…(%)',
            'å¤–è³‡æ˜¨æ—¥è²·è¶…(å¼µ)', 'å¤–è³‡å‰ä¸‰æ—¥ç¸½è²·è¶…(å¼µ)',
            'æŠ•ä¿¡æ˜¨æ—¥è²·è¶…(å¼µ)', 'æŠ•ä¿¡å‰ä¸‰æ—¥ç¸½è²·è¶…(å¼µ)'
        ]

        df_output = df_output.sort_values('ç•¶ä¸‹æ¼²è·Œå¹…(%)', ascending=False)

        # å„²å­˜åˆ° data/latest ç›®éŒ„ï¼ˆæ”¯æ´å¾ python/ æˆ–æ ¹ç›®éŒ„åŸ·è¡Œï¼‰
        output_file = '../data/latest/éš”æ—¥è¡_ç¯©é¸çµæœ.csv' if os.path.exists('../data/latest') else 'data/latest/éš”æ—¥è¡_ç¯©é¸çµæœ.csv'
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        df_output.to_csv(output_file, index=False, encoding='utf-8-sig')

        print(f"\nâœ… ç¯©é¸çµæœå·²å„²å­˜è‡³: {output_file}")
        print("\n" + "=" * 80)
        print("ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨æ¸…å–®ï¼š")
        print("=" * 80)
        print(df_output.to_string(index=False))
    else:
        print("\nâš ï¸  ä»Šå¤©æ²’æœ‰è‚¡ç¥¨ç¬¦åˆæ‰€æœ‰æ¢ä»¶")

        # å³ä½¿æ²’æœ‰è³‡æ–™ä¹Ÿå»ºç«‹ç©ºæª”æ¡ˆ
        df_empty = pd.DataFrame(columns=[
            'è‚¡ç¥¨ä»£ç¢¼', 'å…¬å¸åç¨±', 'ç•¶ä¸‹åƒ¹æ ¼', 'ç•¶ä¸‹æ¼²è·Œå¹…(%)',
            'å¤–è³‡æ˜¨æ—¥è²·è¶…(å¼µ)', 'å¤–è³‡å‰ä¸‰æ—¥ç¸½è²·è¶…(å¼µ)',
            'æŠ•ä¿¡æ˜¨æ—¥è²·è¶…(å¼µ)', 'æŠ•ä¿¡å‰ä¸‰æ—¥ç¸½è²·è¶…(å¼µ)'
        ])
        output_file = '../data/latest/éš”æ—¥è¡_ç¯©é¸çµæœ.csv' if os.path.exists('../data/latest') else 'data/latest/éš”æ—¥è¡_ç¯©é¸çµæœ.csv'
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        df_empty.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ… ç©ºçµæœå·²å„²å­˜è‡³: {output_file}")

    return True

def main():
    """
    ä¸»ç¨‹å¼
    """
    print_header("éš”æ—¥è¡ç­–ç•¥ - éšæ®µ2: å³æ™‚ç¯©é¸")
    print(f"ğŸ“… åŸ·è¡Œæ—¥æœŸ: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %A')}")
    print(f"â° å•Ÿå‹•æ™‚é–“: {datetime.now().strftime('%H:%M:%S')}")
    print_separator()

    # è®€å– token
    token = load_token()

    # åŸ·è¡Œéšæ®µ2ï¼šå³æ™‚ç¯©é¸
    success = realtime_screen(token)

    if success:
        print("\n" + "=" * 80)
        print("ğŸ‰ éšæ®µ2å®Œæˆï¼ç¯©é¸çµæœå·²è¼¸å‡º")
        print("=" * 80)
    else:
        print("\n" + "=" * 80)
        print("âŒ éšæ®µ2å¤±æ•—")
        print("=" * 80)
        exit(1)

if __name__ == "__main__":
    main()
